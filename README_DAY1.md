# üöÄ Day 1: Backend Foundation - Complete Package

## üì¶ What You Have

### Core Files Created:
- ‚úÖ `fast_chatbot_api.py` - Main Flask API with ChatGPT-like functionality
- ‚úÖ `index.html` - Professional ChatGPT-style chat interface
- ‚úÖ `landing.html` - Beautiful landing page with features showcase
- ‚úÖ `setup_vm.sh` - Complete VM setup script
- ‚úÖ `deploy_api.sh` - Production deployment script
- ‚úÖ `setup_frontend.sh` - Frontend deployment script
- ‚úÖ `test_api.sh` - Comprehensive testing script
- ‚úÖ `quick_start.sh` - Fast setup for development
- ‚úÖ `install_ollama.sh` - Ollama-only installation
- ‚úÖ `requirements.txt` - Python dependencies
- ‚úÖ `.env` - Configuration file
- ‚úÖ `DAY1_SETUP_GUIDE.md` - Detailed setup instructions

## üéØ Day 1 Execution Plan

### Morning (2-3 hours): Infrastructure Setup

1. **Create Google Cloud VM**
   ```bash
   # VM Specs:
   # - Machine: e2-standard-2 (2 vCPU, 8GB RAM)
   # - OS: Ubuntu 22.04 LTS
   # - Disk: 20GB
   # - Firewall: Allow HTTP/HTTPS
   ```

2. **Upload all files to your VM**
   - Use `scp` or Google Cloud Console file transfer
   - Place files in `/home/username/` directory

3. **Run the setup script**
   ```bash
   chmod +x *.sh
   ./setup_vm.sh
   ```

### Afternoon (2-3 hours): API & Frontend Deployment

4. **Deploy the API**
   ```bash
   ./deploy_api.sh
   ```

5. **Setup Professional Frontend**
   ```bash
   ./setup_frontend.sh
   ```

6. **Test everything**
   ```bash
   ./test_api.sh
   # Or test with external IP:
   ./test_api.sh http://YOUR-EXTERNAL-IP:5000
   ```

## üèóÔ∏è What Gets Built

### Flask API Features:
- **Professional Landing Page**: Beautiful showcase at `http://your-ip:5000/`
- **ChatGPT-like Interface**: Full chat experience at `http://your-ip:5000/chat`
- **Conversation Memory**: Maintains context within sessions
- **Multiple Endpoints**:
  - `GET /` - Landing page with features and stats
  - `GET /chat` - Professional chat interface
  - `POST /chat` - Main chat functionality (API)
  - `GET /health` - System health check
  - `GET /stats` - Usage statistics
  - `POST /webhook/zoho` - Ready for Day 2 Zoho integration
- **Session Management**: Handles multiple concurrent users
- **Mobile Responsive**: Works perfectly on all devices
- **Error Handling**: Robust error handling and fallbacks
- **Production Ready**: Systemd service with auto-restart

### LLM Backend:
- **Ollama** running **Phi-3 Mini** (3.8B parameters)
- **Local Processing**: Complete data privacy
- **API Access**: RESTful interface to the model
- **Conversation Context**: Maintains chat history

## üß™ Testing Your Setup

### Quick Web Test:
1. Open browser to `http://YOUR-VM-IP:5000/` (Landing Page)
2. Click "Start Chatting Now" or visit `http://YOUR-VM-IP:5000/chat`
3. Type "Hello!" and get an AI response
4. Test conversation memory with follow-up questions

### API Test Commands:
```bash
# Health check
curl http://YOUR-IP:5000/health

# Chat test
curl -X POST http://YOUR-IP:5000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Hello, introduce yourself!"}'

# Memory test (same session)
curl -X POST http://YOUR-IP:5000/chat \
  -H "Content-Type: application/json" \
  -H "X-Session-ID: test-123" \
  -d '{"message": "My name is John"}'

curl -X POST http://YOUR-IP:5000/chat \
  -H "Content-Type: application/json" \
  -H "X-Session-ID: test-123" \
  -d '{"message": "What is my name?"}'
```

## ‚úÖ Day 1 Success Criteria

By end of Day 1, you should have:
- [ ] VM running Ubuntu 22.04
- [ ] Ollama installed with Phi-3 Mini model
- [ ] Flask API running on port 5000
- [ ] Professional landing page at `http://your-ip:5000/`
- [ ] Beautiful chat interface at `http://your-ip:5000/chat`
- [ ] API responding to chat requests
- [ ] Conversation memory working
- [ ] Health and stats endpoints functional
- [ ] Mobile-responsive design working
- [ ] System service running automatically

## üîó Ready for Day 2

Your API will be ready for Zoho SalesIQ integration with:
- Webhook endpoint: `http://your-ip:5000/webhook/zoho`
- Stable, production-ready backend
- Full conversation capabilities

## üí° Pro Tips

1. **Save your VM's external IP** - you'll need it for Day 2
2. **Test the web interface** - it's a great way to verify everything works
3. **Monitor with logs**: `sudo journalctl -u personal-ai-assistant -f`
4. **Firewall reminder**: Ensure ports 5000 and 11434 are open

## üö® Troubleshooting

### Common Issues:
- **Ollama not starting**: `sudo systemctl restart ollama`
- **Model not downloading**: Check internet connection, try `ollama pull phi3:mini`
- **API not responding**: Check service status `sudo systemctl status personal-ai-assistant`
- **Port blocked**: `sudo ufw allow 5000`

### Quick Fixes:
```bash
# Restart everything
sudo systemctl restart ollama
sudo systemctl restart personal-ai-assistant

# Check status
sudo systemctl status ollama
sudo systemctl status personal-ai-assistant

# View logs
sudo journalctl -u personal-ai-assistant -f
```

---

**üéâ You're ready to start Day 1! Upload these files to your VM and run the setup script.**
